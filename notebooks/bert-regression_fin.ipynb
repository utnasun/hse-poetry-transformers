{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-11-01 20:27:00.431950: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-01 20:27:00.490455: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-01 20:27:00.490495: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-01 20:27:00.491912: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-01 20:27:00.500672: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-01 20:27:01.746876: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'url': 'https://www.chitalnya.ru/work/3180020/',\n",
       " 'rating': '29',\n",
       " 'views': 33,\n",
       " 'output_text': 'Люблю ли осень? Ты спроси у ели -\\nОна в колючках и не ждёт тепла...\\nЕй хрен один: повсюду лишь метели,\\nКапель ли хнычет ночью со стекла.\\n\\nБагряный лист, ли, кружится прощаясь,\\nЛи фонаря торчащего кадык,\\nНа низком небе пятнами касаясь\\nК луне общаясь, притулился встык.\\n\\nЛюблю ли осень? Ты спроси у ветра.\\nС ним всё равно не сладить в парусах.\\nПо осени ли, по весне для шторма,\\nСпускают их, на реи намотав.\\n\\nПожухлых трав не кошенные дали,\\nЧьих жалких тел охапками нажнут.\\nСпроси у них, о том они мечтали\\nВесной, тогда!? Теперь их просто жгут.\\n\\nПо осени, когда седеют чувства,\\nЗастыли ветви рук на деревах -\\nМне хочется упасть на дно колодца,\\nЧто бы не видеть слёзы на глазах.',\n",
       " 'genre': 'лирика'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "with open('data/poetry_data_train.json', 'r', encoding='utf-8') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset class\n",
    "class PoemRatingDataset(Dataset):\n",
    "    def __init__(self, poems, ratings, tokenizer):\n",
    "        self.poems = poems\n",
    "        self.ratings = ratings\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.poems)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        poem = self.poems[idx]\n",
    "        rating = self.ratings[idx]\n",
    "        encoding = self.tokenizer(\n",
    "            poem,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=512,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        item = {key: val.squeeze(0) for key, val in encoding.items()}\n",
    "        item['labels'] = torch.tensor(rating, dtype=torch.float)\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "poems = [entry['output_text'] for entry in data if float(entry['rating']) > 0 and entry['views'] >= 50]\n",
    "ratings = [float(entry['rating']) for entry in data if float(entry['rating']) > 0 and entry['views'] >= 50]\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('DeepPavlov/rubert-base-cased')\n",
    "dataset = PoemRatingDataset(poems, ratings, tokenizer)\n",
    "\n",
    "# Train-validation split\n",
    "train_size = int(0.95 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel\n",
    "\n",
    "# Model definition\n",
    "class BertForRegression(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BertForRegression, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('DeepPavlov/rubert-base-cased')\n",
    "        self.regressor = torch.nn.Linear(self.bert.config.hidden_size, 1)\n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids=None, labels=None):\n",
    "        outputs = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "        pooled_output = outputs.pooler_output\n",
    "        rating = self.regressor(pooled_output)\n",
    "        if labels is not None:\n",
    "            loss_fn = torch.nn.MSELoss()\n",
    "            loss = loss_fn(rating.view(-1), labels.view(-1))\n",
    "            return loss, rating\n",
    "        return rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at DeepPavlov/rubert-base-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Initialize model, optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = BertForRegression().to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, eps=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/32: 100%|██████████| 2237/2237 [04:38<00:00,  8.03batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 completed. Train Loss: 3669.2557, Validation MSE: 3162.4363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/32: 100%|██████████| 2237/2237 [04:33<00:00,  8.18batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 completed. Train Loss: 3165.4602, Validation MSE: 2861.1584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/32: 100%|██████████| 2237/2237 [04:33<00:00,  8.19batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 completed. Train Loss: 2984.2838, Validation MSE: 2776.5127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/32: 100%|██████████| 2237/2237 [04:32<00:00,  8.20batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 completed. Train Loss: 2937.1735, Validation MSE: 2748.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/32: 100%|██████████| 2237/2237 [04:32<00:00,  8.20batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 completed. Train Loss: 2931.9633, Validation MSE: 2732.2371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/32: 100%|██████████| 2237/2237 [04:31<00:00,  8.24batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 completed. Train Loss: 2908.0497, Validation MSE: 2720.1118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/32: 100%|██████████| 2237/2237 [04:32<00:00,  8.20batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 completed. Train Loss: 2894.6096, Validation MSE: 2709.9883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/32: 100%|██████████| 2237/2237 [04:32<00:00,  8.20batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 completed. Train Loss: 2893.1187, Validation MSE: 2701.1777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/32: 100%|██████████| 2237/2237 [04:32<00:00,  8.22batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 completed. Train Loss: 2880.5236, Validation MSE: 2693.6377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/32: 100%|██████████| 2237/2237 [04:31<00:00,  8.23batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 completed. Train Loss: 2879.8679, Validation MSE: 2687.1343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/32: 100%|██████████| 2237/2237 [04:32<00:00,  8.21batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 completed. Train Loss: 2868.4032, Validation MSE: 2681.2354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/32: 100%|██████████| 2237/2237 [04:31<00:00,  8.23batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 completed. Train Loss: 2859.3086, Validation MSE: 2676.4548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/32: 100%|██████████| 2237/2237 [04:32<00:00,  8.22batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 completed. Train Loss: 2856.3177, Validation MSE: 2672.3147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/32: 100%|██████████| 2237/2237 [04:31<00:00,  8.25batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 completed. Train Loss: 2850.3777, Validation MSE: 2668.9626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/32: 100%|██████████| 2237/2237 [04:31<00:00,  8.23batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 completed. Train Loss: 2850.9102, Validation MSE: 2665.6926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/32: 100%|██████████| 2237/2237 [04:31<00:00,  8.23batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 completed. Train Loss: 2847.5975, Validation MSE: 2662.7878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/32: 100%|██████████| 2237/2237 [04:31<00:00,  8.23batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 completed. Train Loss: 2846.9402, Validation MSE: 2660.1528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/32: 100%|██████████| 2237/2237 [04:31<00:00,  8.24batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 completed. Train Loss: 2849.7261, Validation MSE: 2657.9385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/32: 100%|██████████| 2237/2237 [04:31<00:00,  8.24batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 completed. Train Loss: 2843.7281, Validation MSE: 2655.6018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/32: 100%|██████████| 2237/2237 [04:31<00:00,  8.24batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 completed. Train Loss: 2839.0633, Validation MSE: 2653.9353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/32: 100%|██████████| 2237/2237 [04:30<00:00,  8.26batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 completed. Train Loss: 2842.6346, Validation MSE: 2652.2273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/32: 100%|██████████| 2237/2237 [04:31<00:00,  8.23batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 completed. Train Loss: 2839.5618, Validation MSE: 2650.7461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/32: 100%|██████████| 2237/2237 [04:30<00:00,  8.27batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 completed. Train Loss: 2839.7816, Validation MSE: 2649.1301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/32: 100%|██████████| 2237/2237 [04:31<00:00,  8.23batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 completed. Train Loss: 2836.2177, Validation MSE: 2647.8801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/32: 100%|██████████| 2237/2237 [04:30<00:00,  8.26batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 completed. Train Loss: 2834.0895, Validation MSE: 2646.8328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/32: 100%|██████████| 2237/2237 [04:31<00:00,  8.23batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 completed. Train Loss: 2833.2021, Validation MSE: 2645.7217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/32: 100%|██████████| 2237/2237 [04:31<00:00,  8.23batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 completed. Train Loss: 2830.6131, Validation MSE: 2644.9097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/32: 100%|██████████| 2237/2237 [04:30<00:00,  8.26batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 completed. Train Loss: 2829.6218, Validation MSE: 2644.1179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/32: 100%|██████████| 2237/2237 [04:31<00:00,  8.23batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 completed. Train Loss: 2828.0773, Validation MSE: 2643.3384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/32: 100%|██████████| 2237/2237 [04:31<00:00,  8.24batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 completed. Train Loss: 2831.0470, Validation MSE: 2642.1218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/32: 100%|██████████| 2237/2237 [04:31<00:00,  8.24batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 completed. Train Loss: 2830.2438, Validation MSE: 2641.7744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/32: 100%|██████████| 2237/2237 [04:31<00:00,  8.25batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 completed. Train Loss: 2829.2167, Validation MSE: 2641.1838\n"
     ]
    }
   ],
   "source": [
    "# Training with validation metrics\n",
    "num_epochs = 32\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    total_train_loss = 0\n",
    "    model.train()\n",
    "    for batch in tqdm(train_dataloader, desc=f'Epoch {epoch + 1}/{num_epochs}', unit='batch'):\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        token_type_ids = batch.get('token_type_ids', None).to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        loss, _ = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            labels=labels\n",
    "        )\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_predictions = []\n",
    "    val_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_dataloader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            token_type_ids = batch.get('token_type_ids', None).to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "    \n",
    "            loss, predictions = model(\n",
    "                        input_ids=input_ids,\n",
    "                        attention_mask=attention_mask,\n",
    "                        token_type_ids=token_type_ids,\n",
    "                        labels=labels\n",
    "                    )\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            val_predictions.extend(predictions.cpu().numpy().flatten())\n",
    "            val_labels.extend(labels.cpu().numpy().flatten())\n",
    "\n",
    "        val_mse = mean_squared_error(val_labels, val_predictions)\n",
    "        print(f'Epoch {epoch+1} completed. Train Loss: {total_train_loss / len(train_dataloader):.4f}, Validation MSE: {val_mse:.4f}')\n",
    "\n",
    "    # Save the model and tokenizer\n",
    "    os.mkdir(f'models_checkpoints/{epoch}')\n",
    "    torch.save(model.state_dict(), f'models_checkpoints/{epoch}/regression_poem_rating_model_filtered.pth')\n",
    "    tokenizer.save_pretrained(f'models_checkpoints/{epoch}/regression_poem_rating_model_filtered')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Расчет NDCG на отложенной выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'url': 'https://www.chitalnya.ru/work/2999707/',\n",
       " 'rating': '0',\n",
       " 'views': 15,\n",
       " 'output_text': 'Нынче головы четыре у дракона,\\nПожиратель президентов он мастак.\\nНа него управы нет, и нет закона,\\nВ споре с ним же попадёт любой впросак.\\n\\nУ него в кармане сотни триллионов.\\nДля него богач - обычный нищеброд.\\nНету больше никаких на свете тронов,\\nНи во что не ставит он любой народ.\\n\\nОн прикажет слугам - выпилить любого\\nС интернета, те его прогонят прочь,\\nИ никто не пикнет, не промолвит слова,\\nНекому бедняге на земле помочь.\\n\\nИ всё потому, что присягнули змею,\\nОтступив от Бога, скорбен наш удел.\\nСлужат люди молча мерзкому пигмею,\\nПоголовно, будто вовсе оборзев.\\n\\nНынче люди лживы, врут напраполую.\\nОн сегодня баба, завтра же мужик.\\nГрабят, убивают, даже мать родную\\nМогут погубить, коль сам дракон велит.\\n\\nВремена драконьи - времена инферно.\\nКовид пандемия - следствие его,\\nОбезумевши, спешит планету ввергнуть\\nВ бездну - так уже желает бошинство.',\n",
       " 'genre': 'лирика'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "with open('data/poetry_data_test.json', 'r', encoding='utf-8') as file:\n",
    "    test_data = json.load(file)\n",
    "\n",
    "\n",
    "test_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at DeepPavlov/rubert-base-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '/root/work/bert_regression/regression_poem_rating_model_filtered.pth'\n",
    "model = BertForRegression()\n",
    "\n",
    "model.load_state_dict(torch.load(path, weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "poems = [entry['output_text'] for entry in test_data]\n",
    "ratings = [float(entry['rating']) for entry in test_data]\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('DeepPavlov/rubert-base-cased')\n",
    "test_dataset = PoemRatingDataset(poems, ratings, tokenizer)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1082 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1082/1082 [04:51<00:00,  3.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG Score: 0.6982737505125434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import ndcg_score\n",
    "import numpy as np\n",
    "from tqdm import tqdm \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()  \n",
    "\n",
    "all_predictions = []\n",
    "all_true_ratings = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_dataloader):\n",
    "        inputs = batch['input_ids']\n",
    "        attention_mask = batch['attention_mask'] \n",
    "        \n",
    "        inputs = inputs.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "\n",
    "        outputs = model(inputs, attention_mask=attention_mask)\n",
    "        predictions = outputs.cpu().numpy()\n",
    "\n",
    "        all_predictions.extend(predictions.flatten())\n",
    "        all_true_ratings.extend(batch['labels'].cpu().numpy())\n",
    "\n",
    "y_true = np.array(all_true_ratings)\n",
    "y_scores = np.array(all_predictions)\n",
    "\n",
    "y_true_reshaped = y_true.reshape(1, -1)  # Reshape to match the expected input shape\n",
    "y_scores_reshaped = y_scores.reshape(1, -1)\n",
    "\n",
    "ndcg = ndcg_score(y_true_reshaped, y_scores_reshaped)\n",
    "\n",
    "print(f\"NDCG Score: {ndcg}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pairwise Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairwisePoemRankingDataset(Dataset):\n",
    "    def __init__(self, poems, ratings, tokenizer):\n",
    "        self.poems = poems\n",
    "        self.ratings = ratings\n",
    "        self.tokenizer = tokenizer\n",
    "        self.pairs = self.create_pairs()\n",
    "\n",
    "    def create_pairs(self):\n",
    "        # Create pairs of (poem1, poem2, label), where label is 1 if poem1 > poem2, otherwise 0\n",
    "        pairs = []\n",
    "        for i in range(len(self.poems)):\n",
    "            for j in range(i + 1, len(self.poems)):\n",
    "                if self.ratings[i] != self.ratings[j]:\n",
    "                    higher = i if self.ratings[i] > self.ratings[j] else j\n",
    "                    lower = j if higher == i else i\n",
    "                    pairs.append((self.poems[higher], self.poems[lower], 1))  # higher should rank above lower\n",
    "                    pairs.append((self.poems[lower], self.poems[higher], 0))  # lower should rank below higher\n",
    "        return pairs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        poem1, poem2, label = self.pairs[idx]\n",
    "        encoding1 = self.tokenizer(\n",
    "            poem1,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=512,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        encoding2 = self.tokenizer(\n",
    "            poem2,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=512,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        item = {\n",
    "            'input_ids1': encoding1['input_ids'].squeeze(0),\n",
    "            'attention_mask1': encoding1['attention_mask'].squeeze(0),\n",
    "            'input_ids2': encoding2['input_ids'].squeeze(0),\n",
    "            'attention_mask2': encoding2['attention_mask'].squeeze(0),\n",
    "            'labels': torch.tensor(label, dtype=torch.float)\n",
    "        }\n",
    "        return item\n",
    "\n",
    "\n",
    "dataset = PairwisePoemRankingDataset(poems, ratings, tokenizer)\n",
    "\n",
    "# Train-validation split\n",
    "train_size = int(0.95 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at DeepPavlov/rubert-base-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Pairwise ranking model\n",
    "class BertForPairwiseRanking(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BertForPairwiseRanking, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('DeepPavlov/rubert-base-cased')\n",
    "        self.regressor = torch.nn.Linear(self.bert.config.hidden_size, 1)\n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def forward(self, input_ids1, attention_mask1, input_ids2, attention_mask2, labels=None):\n",
    "        # Forward pass for the first input\n",
    "        outputs1 = self.bert(input_ids=input_ids1, attention_mask=attention_mask1)\n",
    "        pooled_output1 = outputs1.pooler_output\n",
    "        score1 = self.regressor(pooled_output1)\n",
    "\n",
    "        # Forward pass for the second input\n",
    "        outputs2 = self.bert(input_ids=input_ids2, attention_mask=attention_mask2)\n",
    "        pooled_output2 = outputs2.pooler_output\n",
    "        score2 = self.regressor(pooled_output2)\n",
    "\n",
    "        # Pairwise ranking loss\n",
    "        if labels is not None:\n",
    "            # Ranking loss: Margin-based hinge loss\n",
    "            margin = 1.0\n",
    "            ranking_loss = torch.nn.MarginRankingLoss(margin=margin)\n",
    "            target = 2 * labels - 1  # Convert 0/1 label to -1/1 for ranking loss\n",
    "            loss = ranking_loss(score1.view(-1), score2.view(-1), target)\n",
    "            return loss, score1, score2\n",
    "        return score1, score2\n",
    "\n",
    "# Initialize model, optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = BertForPairwiseRanking().to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, eps=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3:   0%|          | 0/48035348 [01:22<?, ?batch/s]\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[72], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m total_train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     12\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m---> 13\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mEpoch \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mepoch\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;250;43m \u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbatch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids1\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_ids1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pretr\\OneDrive\\Рабочий стол\\Masters\\generative_models\\.venv\\Lib\\site-packages\\tqdm\\std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[0;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[0;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[1;32mc:\\Users\\pretr\\OneDrive\\Рабочий стол\\Masters\\generative_models\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\pretr\\OneDrive\\Рабочий стол\\Masters\\generative_models\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:672\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n",
      "File \u001b[1;32mc:\\Users\\pretr\\OneDrive\\Рабочий стол\\Masters\\generative_models\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:620\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter._next_index\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    619\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_index\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 620\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sampler_iter\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pretr\\OneDrive\\Рабочий стол\\Masters\\generative_models\\.venv\\Lib\\site-packages\\torch\\utils\\data\\sampler.py:288\u001b[0m, in \u001b[0;36mBatchSampler.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    286\u001b[0m batch \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size\n\u001b[0;32m    287\u001b[0m idx_in_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 288\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msampler\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    289\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx_in_batch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43midx_in_batch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\n",
      "File \u001b[1;32mc:\\Users\\pretr\\OneDrive\\Рабочий стол\\Masters\\generative_models\\.venv\\Lib\\site-packages\\torch\\utils\\data\\sampler.py:168\u001b[0m, in \u001b[0;36mRandomSampler.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n):\n\u001b[1;32m--> 168\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandperm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mrandperm(n, generator\u001b[38;5;241m=\u001b[39mgenerator)\u001b[38;5;241m.\u001b[39mtolist()[:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples \u001b[38;5;241m%\u001b[39m n]\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Function to calculate Accuracy@K\n",
    "def accuracy_at_k(labels, predictions, k=5):\n",
    "    top_k_indices = np.argsort(predictions)[-k:]\n",
    "    top_k_labels = labels[top_k_indices]\n",
    "    return np.mean(top_k_labels)\n",
    "\n",
    "# Training with validation\n",
    "num_epochs = 3\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    total_train_loss = 0\n",
    "    model.train()\n",
    "    for batch in tqdm(train_dataloader, desc=f'Epoch {epoch + 1}/{num_epochs}', unit='batch'):\n",
    "        optimizer.zero_grad()\n",
    "        input_ids1 = batch['input_ids1'].to(device)\n",
    "        attention_mask1 = batch['attention_mask1'].to(device)\n",
    "        input_ids2 = batch['input_ids2'].to(device)\n",
    "        attention_mask2 = batch['attention_mask2'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        loss, _, _ = model(\n",
    "            input_ids1=input_ids1,\n",
    "            attention_mask1=attention_mask1,\n",
    "            input_ids2=input_ids2,\n",
    "            attention_mask2=attention_mask2,\n",
    "            labels=labels\n",
    "        )\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_predictions = []\n",
    "    val_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_dataloader:\n",
    "            input_ids1 = batch['input_ids1'].to(device)\n",
    "            attention_mask1 = batch['attention_mask1'].to(device)\n",
    "            input_ids2 = batch['input_ids2'].to(device)\n",
    "            attention_mask2 = batch['attention_mask2'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            loss, score1, score2 = model(\n",
    "                input_ids1=input_ids1,\n",
    "                attention_mask1=attention_mask1,\n",
    "                input_ids2=input_ids2,\n",
    "                attention_mask2=attention_mask2,\n",
    "                labels=labels\n",
    "            )\n",
    "            val_loss += loss.item()\n",
    "            val_predictions.extend(score1.cpu().numpy())\n",
    "            val_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    val_accuracy = accuracy_score(val_labels, (np.array(val_predictions) > 0.5).astype(int))\n",
    "    acc_at_k = accuracy_at_k(np.array(val_labels), np.array(val_predictions), k=5)\n",
    "    \n",
    "    print(f'Epoch {epoch+1} completed. Train Loss: {total_train_loss / len(train_dataloader):.4f}, Validation Accuracy: {val_accuracy:.4f}, Accuracy@5: {acc_at_k:.4f}')\n",
    "\n",
    "    torch.save(model.state_dict(), f'models_checkpoints/{epoch}/pairwise_poem_rating_model_filtered.pth')\n",
    "    tokenizer.save_pretrained(f'models_checkpoints/{epoch}/pairwise_poem_rating_model_filtered')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
